{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assignment3",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mOAhSpYJBv8"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8YeLgmsJ2xP"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "  def __init__(self,input_dimension,embedding_dimension,hidden_dimension,layers,dropout,cell_type):\n",
        "    #initialising the parameters\n",
        "    super().__init__()\n",
        "    self.hidden_dimension=hidden_dimension\n",
        "    self.layers=layers\n",
        "    self.embedding=nn.Embedding(input_dimension,embedding_dimension)\n",
        "    self.cell_type=cell_type\n",
        "    #selcting the cell type with number of layers in the encoder\n",
        "    if self.cell_type=='LSTM':\n",
        "      nn.rnn=nn.LSTM(embedding_dimension,hidden_dimension,layers,dropout=dropout)\n",
        "    elif self.cell_type=='RNN':\n",
        "      nn.rnn=nn.RNN(embedding_dimension,hidden_dimension,layers,dropout=dropout)\n",
        "    else:\n",
        "      nn.rnn=nn.GRU(embedding_dimension,hidden_dimension,layers,dropout=dropout)\n",
        "\n",
        "      #adding the dropout\n",
        "    self.dropout=nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self,source):\n",
        "      embedded=self.dropout(self.embedding(source))\n",
        "      outputs,(hidden,cell)=self.rnn(embedded)\n",
        "      return hidden,cell"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8YRhc5h6N_ky"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "  def __init__(self,output_dimension,embedding_dimension,hidden_dimension,layers,dropout,cell_type):\n",
        "    super().__init__()\n",
        "    self.output_dimension=output_dimension\n",
        "    self.hidden_dimension=hidden_dimension\n",
        "    self.layer=layers\n",
        "    self.embedding=nn.Embedding(output_dimension,embedding_dimension)\n",
        "    self.cell_type=cell_type\n",
        "    if self.cell_type=='LSTM':\n",
        "      nn.rnn=nn.LSTM(embedding_dimension,hidden_dimension,layers,dropout=dropout)\n",
        "    elif self.cell_type=='RNN':\n",
        "      nn.rnn=nn.RNN(embedding_dimension,hidden_dimension,layers,dropout=dropout)\n",
        "    else:\n",
        "      nn.rnn=nn.GRU(embedding_dimension,hidden_dimension,layers,dropout=dropout)\n",
        "    \n",
        "    self.fully_connected=nn.Linear(hidden_dimension,output_dimension)\n",
        "    self.dropout=nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self,input,hidden_cell):\n",
        "      input=input.unsqueeze(0)\n",
        "      embedded=self.dropout(self.embedding(input))\n",
        "      output,(hidden,cell)=self.rnn(embedded,(hidden,cell))\n",
        "      prediction=self.fully_connected(output.squeeze(0))\n",
        "      return predicton,hidden,cell"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3btX0HUmKMEE"
      },
      "source": [
        "class seq_to_seq(nn.Module):\n",
        "  def __init__(self,encoder,decoder,device):\n",
        "    super().__init__()\n",
        "    self.encoder=encoder\n",
        "    self.decoder=decoder\n",
        "    self.device=device\n",
        "\n",
        "  def forward(self,source,target,teacher_forcing_ratio=0.5):\n",
        "    batch_size=target.shape[1]\n",
        "    target_length=target.shape[0]\n",
        "    target_vocab_size=self.decoder.output_dimension\n",
        "    output=torch.zeros(target_length,batch_size,target_vocab_size)\n",
        "    hidden_cell=self.encoder(source)\n",
        "    input = target[0,:]\n",
        "    for t in range(1, target_length):\n",
        "        output, hidden, cell = self.decoder(input, hidden, cell)\n",
        "        outputs[t] = output\n",
        "        teacher_force = random.random() < teacher_forcing_ratio\n",
        "        top1 = output.argmax(1)\n",
        "        input = trg[t] if teacher_force else top1   \n",
        "    return outputs"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cLbYatfHip0A",
        "outputId": "f67ec930-d3a0-4351-fe9d-ff15ec995d0b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CgY3qCspi-kZ"
      },
      "source": [
        "train_data=\"/content/drive/MyDrive/Colab Notebooks/lexicons/hi.translit.sampled.train.tsv\""
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AA9Bd93yjWzz"
      },
      "source": [
        "input_texts = []\n",
        "target_texts = []\n",
        "input_characters = set()\n",
        "target_characters = set()\n",
        "with open(train_data, \"r\", encoding=\"utf-8\") as f:\n",
        "    lines = f.read().split(\"\\n\")\n",
        "for line in lines[: min(44204, len(lines) - 1)]:\n",
        "    target_text, input_text,_ = line.split(\"\\t\")\n",
        "    # We use \"tab\" as the \"start sequence\" character\n",
        "    # for the targets, and \"\\n\" as \"end sequence\" character.\n",
        "    target_text = \"\\t\" + target_text + \"\\n\"\n",
        "    input_texts.append(input_text)\n",
        "    target_texts.append(target_text)\n",
        "    for char in input_text:\n",
        "        if char not in input_characters:\n",
        "            input_characters.add(char)\n",
        "    for char in target_text:\n",
        "        if char not in target_characters:\n",
        "            target_characters.add(char)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVw5e-bPjwlu"
      },
      "source": [
        "input_characters = sorted(list(input_characters))\n",
        "target_characters = sorted(list(target_characters))\n",
        "num_encoder_tokens = len(input_characters)\n",
        "num_decoder_tokens = len(target_characters)\n",
        "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
        "max_decoder_seq_length = max([len(txt) for txt in target_texts])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sc9AUAzHkNp6"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cqrpto1AkFyg"
      },
      "source": [
        "input_token_index = dict([(char, i) for i, char in enumerate(input_characters)])\n",
        "target_token_index = dict([(char, i) for i, char in enumerate(target_characters)])\n",
        "encoder_input_data = np.zeros(\n",
        "    (len(input_texts), max_encoder_seq_length, num_encoder_tokens+1), dtype=\"float32\"\n",
        ")\n",
        "decoder_input_data = np.zeros(\n",
        "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens+1), dtype=\"float32\"\n",
        ")\n",
        "decoder_target_data = np.zeros(\n",
        "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens+1), dtype=\"float32\"\n",
        ")"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MuwLd5mukKhA"
      },
      "source": [
        "input_token_index[\" \"]=26\n",
        "target_token_index[\" \"]=65"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BWYq_r5kURL"
      },
      "source": [
        "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
        "    for t, char in enumerate(input_text):\n",
        "        encoder_input_data[i, t, input_token_index[char]] = 1.0\n",
        "    encoder_input_data[i, t + 1 :, input_token_index[\" \"]] = 1.0\n",
        "    for t, char in enumerate(target_text):\n",
        "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
        "        decoder_input_data[i, t, target_token_index[char]] = 1.0\n",
        "        if t > 0:\n",
        "            # decoder_target_data will be ahead by one timestep\n",
        "            # and will not include the start character.\n",
        "            decoder_target_data[i, t - 1, target_token_index[char]] = 1.0\n",
        "    decoder_input_data[i, t + 1 :, target_token_index[\" \"]] = 1.0\n",
        "    decoder_target_data[i, t:, target_token_index[\" \"]] = 1.0"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pirmXb3FkdRN"
      },
      "source": [
        "def weight_intialisation(m):\n",
        "    for name, param in m.named_parameters():\n",
        "        nn.init.uniform_(param.data, -0.08, 0.08)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3EjEkLpmFhl"
      },
      "source": [
        "INPUT_DIM = len(input_token_index)\n",
        "OUTPUT_DIM = len(target_token_index)\n",
        "ENC_EMB_DIM = 256\n",
        "DEC_EMB_DIM = 256\n",
        "HID_DIM = 512\n",
        "N_LAYERS = 2\n",
        "ENC_DROPOUT = 0.5\n",
        "DEC_DROPOUT = 0.5\n",
        "cell_type='LSTM'\n",
        "\n",
        "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT,cell_type)\n",
        "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT,cell_type)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model = seq_to_seq(enc, dec, device).to(device)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mvJm6DpkmvqO",
        "outputId": "36e2ccf1-4ff0-4393-c090-aab657057e3d"
      },
      "source": [
        "model.apply(weight_intialisation)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "seq_to_seq(\n",
              "  (encoder): Encoder(\n",
              "    (embedding): Embedding(27, 256)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (embedding): Embedding(66, 256)\n",
              "    (fully_connected): Linear(in_features=512, out_features=66, bias=True)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NzWLndXHp9x3"
      },
      "source": [
        "import torch.optim as optim\n",
        "optimizer = optim.Adam(model.parameters())"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGcO3rqrqJsM"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-cXATH6q7xY"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion, clip):\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    for i, batch in enumerate(iterator):\n",
        "        \n",
        "        src = batch.src\n",
        "        trg = batch.trg\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        output = model(src, trg)\n",
        "        \n",
        "        #trg = [trg len, batch size]\n",
        "        #output = [trg len, batch size, output dim]\n",
        "        \n",
        "        output_dim = output.shape[-1]\n",
        "        \n",
        "        output = output[1:].view(-1, output_dim)\n",
        "        trg = trg[1:].view(-1)\n",
        "        \n",
        "        #trg = [(trg len - 1) * batch size]\n",
        "        #output = [(trg len - 1) * batch size, output dim]\n",
        "        \n",
        "        loss = criterion(output, trg)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZbhTVIPtkLr"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for i, batch in enumerate(iterator):\n",
        "\n",
        "            src = batch.src\n",
        "            trg = batch.trg\n",
        "\n",
        "            output = model(src, trg, 0) #turn off teacher forcing\n",
        "\n",
        "            #trg = [trg len, batch size]\n",
        "            #output = [trg len, batch size, output dim]\n",
        "\n",
        "            output_dim = output.shape[-1]\n",
        "            \n",
        "            output = output[1:].view(-1, output_dim)\n",
        "            trg = trg[1:].view(-1)\n",
        "\n",
        "            #trg = [(trg len - 1) * batch size]\n",
        "            #output = [(trg len - 1) * batch size, output dim]\n",
        "\n",
        "            loss = criterion(output, trg)\n",
        "            \n",
        "            epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OayWzh6g4gqH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}